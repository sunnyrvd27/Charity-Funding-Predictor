{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPCEb4juDPDcTdPlDwLIoe+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunnyrvd27/deeplearning_assignment/blob/main/AlphabetSoupCharity_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi7pA6gyu93R",
        "outputId": "54f140b7-585d-476e-f4dc-1bfdc0b498a7"
      },
      "source": [
        "!pip install keras-tuner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.41.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "suOC2lkhw2TF",
        "outputId": "c387295b-cf78-4515-ed9c-940e1b9e41f1"
      },
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd \n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bc40d1d5-b6c3-4a9a-bc6b-9226ee657934\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bc40d1d5-b6c3-4a9a-bc6b-9226ee657934\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving charity_data.csv to charity_data (3).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "3kIzEP-WxAbt",
        "outputId": "525bd67e-e3af-439c-f0de-00e1a62edc2b"
      },
      "source": [
        "import io\n",
        "\n",
        "application_df = pd.read_csv(io.BytesIO(uploaded['charity_data.csv']))\n",
        "application_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        EIN                                      NAME  ... ASK_AMT IS_SUCCESSFUL\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB  ...    5000             1\n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR  ...  108590             1\n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS  ...    5000             0\n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION  ...    6692             1\n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT  ...  142590             1\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VAzZufm66ZE5",
        "outputId": "afc32df3-6961-4e48-f8aa-1598febc1a33"
      },
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop(labels=[\"EIN\", \"NAME\"], axis=1)\n",
        "application_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  APPLICATION_TYPE       AFFILIATION  ... ASK_AMT IS_SUCCESSFUL\n",
              "0              T10       Independent  ...    5000             1\n",
              "1               T3       Independent  ...  108590             1\n",
              "2               T5  CompanySponsored  ...    5000             0\n",
              "3               T3  CompanySponsored  ...    6692             1\n",
              "4               T3       Independent  ...  142590             1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBfBuldkxNCc",
        "outputId": "e74652ef-4004-4d4b-a0fd-2254f83359fe"
      },
      "source": [
        "application_df.nunique()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE            17\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION              71\n",
              "USE_CASE                     5\n",
              "ORGANIZATION                 4\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPos8E326gII"
      },
      "source": [
        "For the optimization, we will bin the following 3 fields \"APPLICATION_TYPE\", \"CLASSIFICATION\" and \"INCOME_AMT\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Af7ubnWxSq8",
        "outputId": "92d8951f-c2f0-47d5-f605-46f9af4252c2"
      },
      "source": [
        "application_type = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
        "application_type\n",
        "\n",
        "# use the variable name `application_types_to_replace`\n",
        "application_types_to_replace = list(application_type[application_type < 500].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PTc-iX5xWcU",
        "outputId": "66324210-10cd-4177-9d4c-8f4a6d5c500d"
      },
      "source": [
        "classification_type = application_df[\"CLASSIFICATION\"].value_counts()\n",
        "classification_type\n",
        "\n",
        "# use the variable name `classifications_to_replace`\n",
        "classifications_to_replace = list(classification_type[classification_type < 1000].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "Other     2261\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK1dJZ488Ql6",
        "outputId": "b881200f-e73c-4dd0-f421-18a964186144"
      },
      "source": [
        "application_df.nunique()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE             9\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION               6\n",
              "USE_CASE                     5\n",
              "ORGANIZATION                 4\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcTfe8_k8UmJ",
        "outputId": "821cac0b-c322-40c4-cc0b-ae3605b94c06"
      },
      "source": [
        "income_amt_type = application_df[\"INCOME_AMT\"].value_counts()\n",
        "income_amt_type"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                24388\n",
              "25000-99999       3747\n",
              "100000-499999     3374\n",
              "1M-5M              955\n",
              "1-9999             728\n",
              "10000-24999        543\n",
              "10M-50M            240\n",
              "5M-10M             185\n",
              "50M+               139\n",
              "Name: INCOME_AMT, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sseLos88fGA"
      },
      "source": [
        "Convert income Amount > 10000 to be merged into \"Other\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckjGwz0F8xzR",
        "outputId": "1c93c92d-3155-46fa-8374-129512e50355"
      },
      "source": [
        "# use the variable name `ask_amt_to_replace`\n",
        "imc_amt_to_replace = list(income_amt_type[income_amt_type < 600].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for imc in imc_amt_to_replace:\n",
        "    application_df['INCOME_AMT'] = application_df['INCOME_AMT'].replace(imc,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df['INCOME_AMT'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                24388\n",
              "25000-99999       3747\n",
              "100000-499999     3374\n",
              "Other             1107\n",
              "1M-5M              955\n",
              "1-9999             728\n",
              "Name: INCOME_AMT, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8kSnSAC9RHJ"
      },
      "source": [
        "USING ONEHOTENCODER TO CREATE FEATURE LIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVgG4Esk9SY2",
        "outputId": "98b75414-2343-4d22-e007-29617a83bb0c"
      },
      "source": [
        "# Using OneHotEncoder to create the features\n",
        "# Generate our categorical variable lists\n",
        "application_cat = list(application_df.dtypes[application_df.dtypes == \"object\"].index)\n",
        "application_cat"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['APPLICATION_TYPE',\n",
              " 'AFFILIATION',\n",
              " 'CLASSIFICATION',\n",
              " 'USE_CASE',\n",
              " 'ORGANIZATION',\n",
              " 'INCOME_AMT',\n",
              " 'SPECIAL_CONSIDERATIONS']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "VeT_N9Lg9YBp",
        "outputId": "1b5866e2-6f9e-4166-e20c-c2b0d1384398"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# Create a OneHotEncoder instance\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit and transform the OneHotEncoder using the categorical variable list\n",
        "encode_df = pd.DataFrame(enc.fit_transform(application_df[application_cat]))\n",
        "\n",
        "# Add the encoded variable names to the dataframe\n",
        "encode_df.columns = enc.get_feature_names(application_cat)\n",
        "encode_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>APPLICATION_TYPE_T7</th>\n",
              "      <th>APPLICATION_TYPE_T8</th>\n",
              "      <th>AFFILIATION_CompanySponsored</th>\n",
              "      <th>AFFILIATION_Family/Parent</th>\n",
              "      <th>AFFILIATION_Independent</th>\n",
              "      <th>AFFILIATION_National</th>\n",
              "      <th>AFFILIATION_Other</th>\n",
              "      <th>AFFILIATION_Regional</th>\n",
              "      <th>CLASSIFICATION_C1000</th>\n",
              "      <th>CLASSIFICATION_C1200</th>\n",
              "      <th>CLASSIFICATION_C2000</th>\n",
              "      <th>CLASSIFICATION_C2100</th>\n",
              "      <th>CLASSIFICATION_C3000</th>\n",
              "      <th>CLASSIFICATION_Other</th>\n",
              "      <th>USE_CASE_CommunityServ</th>\n",
              "      <th>USE_CASE_Heathcare</th>\n",
              "      <th>USE_CASE_Other</th>\n",
              "      <th>USE_CASE_Preservation</th>\n",
              "      <th>USE_CASE_ProductDev</th>\n",
              "      <th>ORGANIZATION_Association</th>\n",
              "      <th>ORGANIZATION_Co-operative</th>\n",
              "      <th>ORGANIZATION_Corporation</th>\n",
              "      <th>ORGANIZATION_Trust</th>\n",
              "      <th>INCOME_AMT_0</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_Other</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   APPLICATION_TYPE_Other  ...  SPECIAL_CONSIDERATIONS_Y\n",
              "0                     0.0  ...                       0.0\n",
              "1                     0.0  ...                       0.0\n",
              "2                     0.0  ...                       0.0\n",
              "3                     0.0  ...                       0.0\n",
              "4                     0.0  ...                       0.0\n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "_Q5SsQch_-85",
        "outputId": "d5f21d1d-f128-4d9c-b71c-30d339adc352"
      },
      "source": [
        "# Merge one-hot encoded features and drop the originals\n",
        "application_df = application_df.merge(encode_df, left_index=True, right_index=True)\n",
        "application_df = application_df.drop(labels=application_cat, axis=1)\n",
        "application_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>APPLICATION_TYPE_T7</th>\n",
              "      <th>APPLICATION_TYPE_T8</th>\n",
              "      <th>AFFILIATION_CompanySponsored</th>\n",
              "      <th>AFFILIATION_Family/Parent</th>\n",
              "      <th>AFFILIATION_Independent</th>\n",
              "      <th>AFFILIATION_National</th>\n",
              "      <th>AFFILIATION_Other</th>\n",
              "      <th>AFFILIATION_Regional</th>\n",
              "      <th>CLASSIFICATION_C1000</th>\n",
              "      <th>CLASSIFICATION_C1200</th>\n",
              "      <th>CLASSIFICATION_C2000</th>\n",
              "      <th>CLASSIFICATION_C2100</th>\n",
              "      <th>CLASSIFICATION_C3000</th>\n",
              "      <th>CLASSIFICATION_Other</th>\n",
              "      <th>USE_CASE_CommunityServ</th>\n",
              "      <th>USE_CASE_Heathcare</th>\n",
              "      <th>USE_CASE_Other</th>\n",
              "      <th>USE_CASE_Preservation</th>\n",
              "      <th>USE_CASE_ProductDev</th>\n",
              "      <th>ORGANIZATION_Association</th>\n",
              "      <th>ORGANIZATION_Co-operative</th>\n",
              "      <th>ORGANIZATION_Corporation</th>\n",
              "      <th>ORGANIZATION_Trust</th>\n",
              "      <th>INCOME_AMT_0</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_Other</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   STATUS  ASK_AMT  ...  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y\n",
              "0       1     5000  ...                       1.0                       0.0\n",
              "1       1   108590  ...                       1.0                       0.0\n",
              "2       1     5000  ...                       1.0                       0.0\n",
              "3       1     6692  ...                       1.0                       0.0\n",
              "4       1   142590  ...                       1.0                       0.0\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgcAjamqAFtW"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "X = application_df.drop(\"IS_SUCCESSFUL\", axis=1).values\n",
        "y = application_df[\"IS_SUCCESSFUL\"].values.reshape(-1, 1)\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRktGEzlAHQ-"
      },
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK1Uc7adAKzf"
      },
      "source": [
        "MODEL 1: Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2z2qL0BARkO",
        "outputId": "1d260683-1d8f-4891-9127-5a93f81b465a"
      },
      "source": [
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 80\n",
        "hidden_nodes_layer2 = 40\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"sigmoid\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"sigmoid\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 80)                3280      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 40)                3240      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 41        \n",
            "=================================================================\n",
            "Total params: 6,561\n",
            "Trainable params: 6,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNoWqXE_Ayrg",
        "outputId": "85e23df7-1d54-4d3b-9e25-550d21c92608"
      },
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=200)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5960 - accuracy: 0.7014\n",
            "Epoch 2/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5764 - accuracy: 0.7187\n",
            "Epoch 3/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5721 - accuracy: 0.7217\n",
            "Epoch 4/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7233\n",
            "Epoch 5/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5629 - accuracy: 0.7246\n",
            "Epoch 6/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5607 - accuracy: 0.7246\n",
            "Epoch 7/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5587 - accuracy: 0.7257\n",
            "Epoch 8/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5575 - accuracy: 0.7262\n",
            "Epoch 9/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5562 - accuracy: 0.7261\n",
            "Epoch 10/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5554 - accuracy: 0.7268\n",
            "Epoch 11/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5547 - accuracy: 0.7268\n",
            "Epoch 12/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5547 - accuracy: 0.7266\n",
            "Epoch 13/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5540 - accuracy: 0.7270\n",
            "Epoch 14/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5532 - accuracy: 0.7278\n",
            "Epoch 15/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5530 - accuracy: 0.7284\n",
            "Epoch 16/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7290\n",
            "Epoch 17/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7290\n",
            "Epoch 18/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5514 - accuracy: 0.7290\n",
            "Epoch 19/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5515 - accuracy: 0.7287\n",
            "Epoch 20/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5512 - accuracy: 0.7289\n",
            "Epoch 21/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5506 - accuracy: 0.7289\n",
            "Epoch 22/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5504 - accuracy: 0.7294\n",
            "Epoch 23/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5500 - accuracy: 0.7296\n",
            "Epoch 24/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.7301\n",
            "Epoch 25/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.7306\n",
            "Epoch 26/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5496 - accuracy: 0.7296\n",
            "Epoch 27/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5491 - accuracy: 0.7297\n",
            "Epoch 28/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5489 - accuracy: 0.7304\n",
            "Epoch 29/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5488 - accuracy: 0.7313\n",
            "Epoch 30/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.7308\n",
            "Epoch 31/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5483 - accuracy: 0.7310\n",
            "Epoch 32/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7316\n",
            "Epoch 33/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7303\n",
            "Epoch 34/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5473 - accuracy: 0.7312\n",
            "Epoch 35/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5474 - accuracy: 0.7318\n",
            "Epoch 36/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5472 - accuracy: 0.7317\n",
            "Epoch 37/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5473 - accuracy: 0.7328\n",
            "Epoch 38/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5469 - accuracy: 0.7318\n",
            "Epoch 39/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.7323\n",
            "Epoch 40/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7331\n",
            "Epoch 41/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7326\n",
            "Epoch 42/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7326\n",
            "Epoch 43/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7327\n",
            "Epoch 44/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7332\n",
            "Epoch 45/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7330\n",
            "Epoch 46/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7331\n",
            "Epoch 47/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7334\n",
            "Epoch 48/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7332\n",
            "Epoch 49/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7336\n",
            "Epoch 50/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7341\n",
            "Epoch 51/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7349\n",
            "Epoch 52/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7348\n",
            "Epoch 53/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7341\n",
            "Epoch 54/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7353\n",
            "Epoch 55/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7347\n",
            "Epoch 56/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7345\n",
            "Epoch 57/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7352\n",
            "Epoch 58/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7339\n",
            "Epoch 59/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7333\n",
            "Epoch 60/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7365\n",
            "Epoch 61/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7358\n",
            "Epoch 62/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7351\n",
            "Epoch 63/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7357\n",
            "Epoch 64/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7353\n",
            "Epoch 65/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7355\n",
            "Epoch 66/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7361\n",
            "Epoch 67/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7360\n",
            "Epoch 68/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7360\n",
            "Epoch 69/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7366\n",
            "Epoch 70/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7353\n",
            "Epoch 71/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7360\n",
            "Epoch 72/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7362\n",
            "Epoch 73/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7362\n",
            "Epoch 74/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7361\n",
            "Epoch 75/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7360\n",
            "Epoch 76/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7355\n",
            "Epoch 77/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7369\n",
            "Epoch 78/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7362\n",
            "Epoch 79/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7354\n",
            "Epoch 80/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7365\n",
            "Epoch 81/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7361\n",
            "Epoch 82/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7361\n",
            "Epoch 83/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7354\n",
            "Epoch 84/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7367\n",
            "Epoch 85/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7368\n",
            "Epoch 86/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7363\n",
            "Epoch 87/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7369\n",
            "Epoch 88/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7372\n",
            "Epoch 89/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7374\n",
            "Epoch 90/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7368\n",
            "Epoch 91/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7367\n",
            "Epoch 92/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7373\n",
            "Epoch 93/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7374\n",
            "Epoch 94/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7371\n",
            "Epoch 95/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7372\n",
            "Epoch 96/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7374\n",
            "Epoch 97/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7373\n",
            "Epoch 98/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7382\n",
            "Epoch 99/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7376\n",
            "Epoch 100/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7386\n",
            "Epoch 101/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7377\n",
            "Epoch 102/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7379\n",
            "Epoch 103/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7377\n",
            "Epoch 104/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7377\n",
            "Epoch 105/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7380\n",
            "Epoch 106/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7384\n",
            "Epoch 107/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7374\n",
            "Epoch 108/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7380\n",
            "Epoch 109/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7380\n",
            "Epoch 110/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7382\n",
            "Epoch 111/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7391\n",
            "Epoch 112/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7381\n",
            "Epoch 113/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7377\n",
            "Epoch 114/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7377\n",
            "Epoch 115/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7369\n",
            "Epoch 116/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7386\n",
            "Epoch 117/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7377\n",
            "Epoch 118/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7377\n",
            "Epoch 119/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7383\n",
            "Epoch 120/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7388\n",
            "Epoch 121/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7386\n",
            "Epoch 122/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7381\n",
            "Epoch 123/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7385\n",
            "Epoch 124/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7379\n",
            "Epoch 125/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7381\n",
            "Epoch 126/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7393\n",
            "Epoch 127/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7390\n",
            "Epoch 128/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7380\n",
            "Epoch 129/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7390\n",
            "Epoch 130/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7391\n",
            "Epoch 131/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7384\n",
            "Epoch 132/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7386\n",
            "Epoch 133/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7384\n",
            "Epoch 134/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7397\n",
            "Epoch 135/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7384\n",
            "Epoch 136/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7392\n",
            "Epoch 137/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7391\n",
            "Epoch 138/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7382\n",
            "Epoch 139/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7395\n",
            "Epoch 140/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7381\n",
            "Epoch 141/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7385\n",
            "Epoch 142/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7379\n",
            "Epoch 143/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7383\n",
            "Epoch 144/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7387\n",
            "Epoch 145/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7385\n",
            "Epoch 146/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7390\n",
            "Epoch 147/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7390\n",
            "Epoch 148/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7385\n",
            "Epoch 149/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7385\n",
            "Epoch 150/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7389\n",
            "Epoch 151/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7386\n",
            "Epoch 152/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7396\n",
            "Epoch 153/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7399\n",
            "Epoch 154/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7382\n",
            "Epoch 155/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7390\n",
            "Epoch 156/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7396\n",
            "Epoch 157/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7387\n",
            "Epoch 158/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7390\n",
            "Epoch 159/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7392\n",
            "Epoch 160/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7377\n",
            "Epoch 161/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7396\n",
            "Epoch 162/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7386\n",
            "Epoch 163/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7390\n",
            "Epoch 164/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7388\n",
            "Epoch 165/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7397\n",
            "Epoch 166/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7392\n",
            "Epoch 167/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7385\n",
            "Epoch 168/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7402\n",
            "Epoch 169/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7392\n",
            "Epoch 170/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7392\n",
            "Epoch 171/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7394\n",
            "Epoch 172/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7384\n",
            "Epoch 173/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7389\n",
            "Epoch 174/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7385\n",
            "Epoch 175/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7397\n",
            "Epoch 176/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7385\n",
            "Epoch 177/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7399\n",
            "Epoch 178/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7390\n",
            "Epoch 179/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7393\n",
            "Epoch 180/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7400\n",
            "Epoch 181/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7393\n",
            "Epoch 182/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7391\n",
            "Epoch 183/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7394\n",
            "Epoch 184/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7390\n",
            "Epoch 185/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7391\n",
            "Epoch 186/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7393\n",
            "Epoch 187/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7392\n",
            "Epoch 188/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7390\n",
            "Epoch 189/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7392\n",
            "Epoch 190/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7390\n",
            "Epoch 191/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7399\n",
            "Epoch 192/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7392\n",
            "Epoch 193/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7392\n",
            "Epoch 194/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7397\n",
            "Epoch 195/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7395\n",
            "Epoch 196/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7394\n",
            "Epoch 197/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7395\n",
            "Epoch 198/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7394\n",
            "Epoch 199/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7400\n",
            "Epoch 200/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f8I3os0A9mn",
        "outputId": "a0ed43dc-c6ef-4ce7-96a9-034e740c3f63"
      },
      "source": [
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5615 - accuracy: 0.7304\n",
            "Loss: 0.561540961265564, Accuracy: 0.7303789854049683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "CRFCyW4eBA5v",
        "outputId": "5ad547e6-8bb7-4170-b3e7-aaf3b06d010f"
      },
      "source": [
        " # Create a DataFrame containing training history\n",
        "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
        "\n",
        "# Plot the accuracy\n",
        "history_df.plot(y=\"accuracy\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f77716c45d0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYDOQGvrJuHH"
      },
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save(\"AlphabetSoupCharity_Optimization_Model1.h5\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETncbhscJ2F-"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6_8hMsXDn0_"
      },
      "source": [
        "MODEL 2: Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bOSpT7NDs09",
        "outputId": "563eaca4-ff4a-4c7b-a92d-905064954a87"
      },
      "source": [
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 80\n",
        "hidden_nodes_layer2 = 80\n",
        "hidden_nodes_layer3 = 30\n",
        "nn = tf.keras.models.Sequential()\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\")\n",
        ")\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"sigmoid\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"sigmoid\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 80)                3280      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 30)                2430      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 12,221\n",
            "Trainable params: 12,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CHlGKQTEYaP",
        "outputId": "3bb569d4-ee46-444d-b10b-cdff12d96f0f"
      },
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=50)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5834 - accuracy: 0.7121\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5651 - accuracy: 0.7244\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5598 - accuracy: 0.7263\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5571 - accuracy: 0.7270\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5555 - accuracy: 0.7284\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5547 - accuracy: 0.7290\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5535 - accuracy: 0.7287\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5528 - accuracy: 0.7301\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5522 - accuracy: 0.7291\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5516 - accuracy: 0.7300\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5509 - accuracy: 0.7311\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5501 - accuracy: 0.7302\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.7303\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5491 - accuracy: 0.7319\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5484 - accuracy: 0.7312\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5482 - accuracy: 0.7313\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5481 - accuracy: 0.7326\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5479 - accuracy: 0.7323\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5470 - accuracy: 0.7334\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7337\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7341\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7334\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7338\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7340\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7340\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7337\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7338\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7358\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7342\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7353\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7347\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7351\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7347\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7357\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7355\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7360\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7353\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7366\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7358\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7360\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7372\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.7364\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5407 - accuracy: 0.7370\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7366\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7366\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5404 - accuracy: 0.7367\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7364\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7372\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7384\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2sY4z6wE_0G",
        "outputId": "3de2baad-9c22-4e3c-854e-a9b1d60c6de9"
      },
      "source": [
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5511 - accuracy: 0.7311\n",
            "Loss: 0.5510879158973694, Accuracy: 0.7310787439346313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "JoXmVPV8FD6l",
        "outputId": "6c5ba034-e614-4045-eebb-2b8035d061d4"
      },
      "source": [
        " # Create a DataFrame containing training history\n",
        "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
        "# Plot the accuracy\n",
        "history_df.plot(y=\"accuracy\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f777081e7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEq884TvKAku"
      },
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save(\"AlphabetSoupCharity_Optimization_Model2.h5\")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPMwUoPzFTe1"
      },
      "source": [
        "MODEL 3: Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_kW2G3IFU8G",
        "outputId": "33b0d738-3620-4f0a-d168-f5865afcdad9"
      },
      "source": [
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 90\n",
        "hidden_nodes_layer2 = 80\n",
        "hidden_nodes_layer3 = 30\n",
        "nn = tf.keras.models.Sequential()\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\")\n",
        ")\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 90)                3690      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 80)                7280      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 30)                2430      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 13,431\n",
            "Trainable params: 13,431\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khZXkZISGEsS",
        "outputId": "6f54af16-dd17-4d77-c997-bdc28dbc5a2c"
      },
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=200)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5719 - accuracy: 0.7186\n",
            "Epoch 2/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5605 - accuracy: 0.7273\n",
            "Epoch 3/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5569 - accuracy: 0.7274\n",
            "Epoch 4/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5549 - accuracy: 0.7275\n",
            "Epoch 5/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5538 - accuracy: 0.7293\n",
            "Epoch 6/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5526 - accuracy: 0.7299\n",
            "Epoch 7/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5513 - accuracy: 0.7299\n",
            "Epoch 8/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5504 - accuracy: 0.7311\n",
            "Epoch 9/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5496 - accuracy: 0.7315\n",
            "Epoch 10/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7314\n",
            "Epoch 11/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5488 - accuracy: 0.7325\n",
            "Epoch 12/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7332\n",
            "Epoch 13/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5472 - accuracy: 0.7337\n",
            "Epoch 14/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7331\n",
            "Epoch 15/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7339\n",
            "Epoch 16/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7347\n",
            "Epoch 17/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7346\n",
            "Epoch 18/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7348\n",
            "Epoch 19/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7352\n",
            "Epoch 20/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7352\n",
            "Epoch 21/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7358\n",
            "Epoch 22/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7362\n",
            "Epoch 23/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7356\n",
            "Epoch 24/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7346\n",
            "Epoch 25/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7367\n",
            "Epoch 26/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7368\n",
            "Epoch 27/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7367\n",
            "Epoch 28/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7372\n",
            "Epoch 29/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5411 - accuracy: 0.7372\n",
            "Epoch 30/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7370\n",
            "Epoch 31/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7383\n",
            "Epoch 32/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7375\n",
            "Epoch 33/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7373\n",
            "Epoch 34/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5402 - accuracy: 0.7372\n",
            "Epoch 35/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5400 - accuracy: 0.7377\n",
            "Epoch 36/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.7359\n",
            "Epoch 37/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5396 - accuracy: 0.7376\n",
            "Epoch 38/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5397 - accuracy: 0.7379\n",
            "Epoch 39/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7375\n",
            "Epoch 40/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5392 - accuracy: 0.7377\n",
            "Epoch 41/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7377\n",
            "Epoch 42/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7387\n",
            "Epoch 43/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7381\n",
            "Epoch 44/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5382 - accuracy: 0.7388\n",
            "Epoch 45/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7385\n",
            "Epoch 46/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7380\n",
            "Epoch 47/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5390 - accuracy: 0.7382\n",
            "Epoch 48/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5381 - accuracy: 0.7390\n",
            "Epoch 49/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5380 - accuracy: 0.7385\n",
            "Epoch 50/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5381 - accuracy: 0.7381\n",
            "Epoch 51/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7394\n",
            "Epoch 52/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7391\n",
            "Epoch 53/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5382 - accuracy: 0.7381\n",
            "Epoch 54/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7384\n",
            "Epoch 55/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7388\n",
            "Epoch 56/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7384\n",
            "Epoch 57/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7387\n",
            "Epoch 58/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7381\n",
            "Epoch 59/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7381\n",
            "Epoch 60/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7386\n",
            "Epoch 61/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7385\n",
            "Epoch 62/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7378\n",
            "Epoch 63/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7376\n",
            "Epoch 64/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7385\n",
            "Epoch 65/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7381\n",
            "Epoch 66/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7392\n",
            "Epoch 67/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7379\n",
            "Epoch 68/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7398\n",
            "Epoch 69/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7378\n",
            "Epoch 70/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7386\n",
            "Epoch 71/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7391\n",
            "Epoch 72/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7387\n",
            "Epoch 73/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7396\n",
            "Epoch 74/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7390\n",
            "Epoch 75/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7391\n",
            "Epoch 76/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7396\n",
            "Epoch 77/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7391\n",
            "Epoch 78/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7393\n",
            "Epoch 79/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7394\n",
            "Epoch 80/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7394\n",
            "Epoch 81/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7392\n",
            "Epoch 82/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7399\n",
            "Epoch 83/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7391\n",
            "Epoch 84/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7391\n",
            "Epoch 85/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7372\n",
            "Epoch 86/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7400\n",
            "Epoch 87/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7391\n",
            "Epoch 88/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7391\n",
            "Epoch 89/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7381\n",
            "Epoch 90/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7390\n",
            "Epoch 91/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7397\n",
            "Epoch 92/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7390\n",
            "Epoch 93/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7392\n",
            "Epoch 94/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7392\n",
            "Epoch 95/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7394\n",
            "Epoch 96/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7389\n",
            "Epoch 97/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7385\n",
            "Epoch 98/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7387\n",
            "Epoch 99/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7396\n",
            "Epoch 100/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7391\n",
            "Epoch 101/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7390\n",
            "Epoch 102/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7387\n",
            "Epoch 103/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7398\n",
            "Epoch 104/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7399\n",
            "Epoch 105/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7395\n",
            "Epoch 106/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7400\n",
            "Epoch 107/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7397\n",
            "Epoch 108/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7389\n",
            "Epoch 109/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7401\n",
            "Epoch 110/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7396\n",
            "Epoch 111/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7397\n",
            "Epoch 112/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7404\n",
            "Epoch 113/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7396\n",
            "Epoch 114/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7397\n",
            "Epoch 115/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7388\n",
            "Epoch 116/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7402\n",
            "Epoch 117/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7395\n",
            "Epoch 118/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7385\n",
            "Epoch 119/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7397\n",
            "Epoch 120/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7396\n",
            "Epoch 121/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7393\n",
            "Epoch 122/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7395\n",
            "Epoch 123/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7399\n",
            "Epoch 124/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7393\n",
            "Epoch 125/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7401\n",
            "Epoch 126/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7397\n",
            "Epoch 127/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7397\n",
            "Epoch 128/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7396\n",
            "Epoch 129/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7406\n",
            "Epoch 130/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7390\n",
            "Epoch 131/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7393\n",
            "Epoch 132/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7395\n",
            "Epoch 133/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7393\n",
            "Epoch 134/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7394\n",
            "Epoch 135/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7401\n",
            "Epoch 136/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7401\n",
            "Epoch 137/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7392\n",
            "Epoch 138/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7406\n",
            "Epoch 139/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7398\n",
            "Epoch 140/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7391\n",
            "Epoch 141/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7403\n",
            "Epoch 142/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7398\n",
            "Epoch 143/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7399\n",
            "Epoch 144/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7397\n",
            "Epoch 145/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7399\n",
            "Epoch 146/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7396\n",
            "Epoch 147/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7402\n",
            "Epoch 148/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7410\n",
            "Epoch 149/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7400\n",
            "Epoch 150/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7402\n",
            "Epoch 151/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7395\n",
            "Epoch 152/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7399\n",
            "Epoch 153/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7401\n",
            "Epoch 154/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7405\n",
            "Epoch 155/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7402\n",
            "Epoch 156/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7393\n",
            "Epoch 157/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7385\n",
            "Epoch 158/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7385\n",
            "Epoch 159/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7393\n",
            "Epoch 160/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.7398\n",
            "Epoch 161/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7404\n",
            "Epoch 162/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7403\n",
            "Epoch 163/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7405\n",
            "Epoch 164/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7391\n",
            "Epoch 165/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.7402\n",
            "Epoch 166/200\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7394\n",
            "Epoch 167/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7402\n",
            "Epoch 168/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7402\n",
            "Epoch 169/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7398\n",
            "Epoch 170/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7402\n",
            "Epoch 171/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.7397\n",
            "Epoch 172/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7402\n",
            "Epoch 173/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7404\n",
            "Epoch 174/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7406\n",
            "Epoch 175/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.7399\n",
            "Epoch 176/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7403\n",
            "Epoch 177/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7404\n",
            "Epoch 178/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7402\n",
            "Epoch 179/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7400\n",
            "Epoch 180/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7395\n",
            "Epoch 181/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7394\n",
            "Epoch 182/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7403\n",
            "Epoch 183/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7394\n",
            "Epoch 184/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7404\n",
            "Epoch 185/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7400\n",
            "Epoch 186/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7402\n",
            "Epoch 187/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7407\n",
            "Epoch 188/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7405\n",
            "Epoch 189/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.7391\n",
            "Epoch 190/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7395\n",
            "Epoch 191/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7385\n",
            "Epoch 192/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7399\n",
            "Epoch 193/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7401\n",
            "Epoch 194/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7405\n",
            "Epoch 195/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7399\n",
            "Epoch 196/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7398\n",
            "Epoch 197/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7396\n",
            "Epoch 198/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7401\n",
            "Epoch 199/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7394\n",
            "Epoch 200/200\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrCqHYCmGI0_",
        "outputId": "9158cc36-d57b-420c-f2a5-fd0586ec5f04"
      },
      "source": [
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5620 - accuracy: 0.7297\n",
            "Loss: 0.562027096748352, Accuracy: 0.72967928647995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "bVdlHlU4GKHo",
        "outputId": "efbb33b4-d9a9-4654-f767-b8287aa72e01"
      },
      "source": [
        " # Create a DataFrame containing training history\n",
        "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
        "# Plot the accuracy\n",
        "history_df.plot(y=\"accuracy\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7767540290>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ekZM1nmKErV"
      },
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save(\"AlphabetSoupCharity_Optimization_Model3.h5\")"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7n3iezzHirX"
      },
      "source": [
        "MODEL 4:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2dNaDAjHkOn",
        "outputId": "22fc6952-44ce-4c21-8183-0be0798d6078"
      },
      "source": [
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 90\n",
        "hidden_nodes_layer2 = 90\n",
        "hidden_nodes_layer3 = 70\n",
        "hidden_nodes_layer4 = 30\n",
        "nn = tf.keras.models.Sequential()\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Fourth hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"sigmoid\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_24 (Dense)             (None, 90)                3690      \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 90)                8190      \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 90)                8190      \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 90)                8190      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 91        \n",
            "=================================================================\n",
            "Total params: 28,351\n",
            "Trainable params: 28,351\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koYWPaPYH6Zm",
        "outputId": "1eae235e-1766-46c3-fdd3-d69d256fbd1b"
      },
      "source": [
        "\n",
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=50)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5722 - accuracy: 0.7164\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5594 - accuracy: 0.7250\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5573 - accuracy: 0.7258\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5556 - accuracy: 0.7275\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5540 - accuracy: 0.7299\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5530 - accuracy: 0.7292\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5522 - accuracy: 0.7305\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5513 - accuracy: 0.7299\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5504 - accuracy: 0.7308\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5498 - accuracy: 0.7323\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5494 - accuracy: 0.7308\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5488 - accuracy: 0.7329\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5482 - accuracy: 0.7331\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5476 - accuracy: 0.7326\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5468 - accuracy: 0.7321\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5471 - accuracy: 0.7325\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5467 - accuracy: 0.7338\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5459 - accuracy: 0.7337\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5459 - accuracy: 0.7338\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5452 - accuracy: 0.7329\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7343\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5445 - accuracy: 0.7334\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5447 - accuracy: 0.7341\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5438 - accuracy: 0.7364\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5435 - accuracy: 0.7348\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7363\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7352\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7355\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7357\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5417 - accuracy: 0.7364\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5416 - accuracy: 0.7369\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7362\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5410 - accuracy: 0.7362\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5410 - accuracy: 0.7372\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5410 - accuracy: 0.7357\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5406 - accuracy: 0.7372\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5401 - accuracy: 0.7376\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5401 - accuracy: 0.7365\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5405 - accuracy: 0.7373\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5408 - accuracy: 0.7374\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5410 - accuracy: 0.7362\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5411 - accuracy: 0.7376\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5394 - accuracy: 0.7375\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5392 - accuracy: 0.7378\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5394 - accuracy: 0.7370\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5393 - accuracy: 0.7366\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7371\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5380 - accuracy: 0.7371\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7372\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T7w8TcaIV0c",
        "outputId": "344f87a7-1fd3-49ba-b4f9-d06aba0fcd8e"
      },
      "source": [
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5581 - accuracy: 0.7307\n",
            "Loss: 0.558124303817749, Accuracy: 0.7307288646697998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "B4jgMihdIbKl",
        "outputId": "adee62cd-a416-430e-b959-4e27c1ecb78d"
      },
      "source": [
        " # Create a DataFrame containing training history\n",
        "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
        "# Plot the accuracy\n",
        "history_df.plot(y=\"accuracy\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7767128950>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yw8LnAuKM8_"
      },
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save(\"AlphabetSoupCharity_Optimization_Model4.h5\")"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jyb5a2c_CUTn"
      },
      "source": [
        "Trying Optimization with Hyperparameter Option"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gcm0gz_CZQV"
      },
      "source": [
        "# Create a method that creates a new Sequential model with hyperparameter options\n",
        "def create_model(hp):\n",
        "    nn_model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
        "    activation = hp.Choice('activation',['relu','tanh','sigmoid'])\n",
        "    \n",
        "    # Allow kerastuner to decide number of neurons in first layer\n",
        "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
        "        min_value=1,\n",
        "        max_value=80,\n",
        "        step=2), activation=activation, input_dim=2))\n",
        "\n",
        "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
        "    for i in range(hp.Int('num_layers', 1, 6)):\n",
        "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
        "            min_value=1,\n",
        "            max_value=60,\n",
        "            step=2),\n",
        "            activation=activation))\n",
        "    \n",
        "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "    # Compile the model\n",
        "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
        "    \n",
        "    return nn_model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYMdX838Cq0O",
        "outputId": "384d2544-4a8e-4b10-e61c-574042046e85"
      },
      "source": [
        " # Import the kerastuner library\n",
        "import kerastuner as kt\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    create_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=20,\n",
        "    hyperband_iterations=2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "LlUS3qcSC9rJ",
        "outputId": "94d7b3a9-1659-40dd-f511-17281a216b2f"
      },
      "source": [
        " # Run the kerastuner search for best hyperparameters\n",
        "tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test_scaled,y_test))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "activation        |relu              |?                 \n",
            "first_units       |77                |?                 \n",
            "num_layers        |1                 |?                 \n",
            "units_0           |11                |?                 \n",
            "tuner/epochs      |2                 |?                 \n",
            "tuner/initial_e...|0                 |?                 \n",
            "tuner/bracket     |3                 |?                 \n",
            "tuner/round       |0                 |?                 \n",
            "\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-eb58256bf280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the kerastuner search for best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \"\"\"\n\u001b[1;32m    148\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:787 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py:254 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape (None, 40)\n"
          ]
        }
      ]
    }
  ]
}